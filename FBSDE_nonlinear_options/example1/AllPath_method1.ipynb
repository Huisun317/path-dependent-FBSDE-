{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bac2f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from scipy.stats import norm\n",
    "import time as ttt\n",
    "import iisignature as iisig\n",
    "from tqdm import *\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e7f4382",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51eebb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "data_type=torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b93a6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 1.0 # initial condition\n",
    "sigma = 1 # volatility\n",
    "mu = 0.02\n",
    "segs=20\n",
    "r = 0.01 # risk free rate\n",
    "batch_size = 1000 # batch size\n",
    "steps=5000\n",
    "T = 1 # maturity\n",
    "dt = T/steps # mesh size\n",
    "true = 0.5828174603130847# true option price\n",
    "\n",
    "dt = T/steps # mesh size\n",
    "dt_new = T/segs # new mesh after shrinkage\n",
    "level = 3 # truncation level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "591fff53",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_in=100\n",
    "MOMENTUM = 0.99\n",
    "EPSILON = 1e-6\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "250e8482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stock2(x0,r,sigma,T,steps,n_path,dW):\n",
    "    dt=T/steps; \n",
    "    sqrt_dt=np.sqrt(dt); \n",
    "    s_vec=[]; w_vec=[]; \n",
    "    w_vec.append(np.ones(n_path)*1e-6)\n",
    "    s_vec.append(np.ones(n_path)*1.0)\n",
    "    for i in range(steps): \n",
    "        w_vec.append(dW[:,i]) \n",
    "        s_vectemp=s_vec[-1]+ r*s_vec[-1]*dt+ w_vec[-1]*s_vec[-1]*sigma\n",
    "        s_vec.append(s_vectemp)\n",
    "    wvec=np.transpose(np.array(w_vec))\n",
    "    BM_path=np.cumsum(wvec,axis=1)\n",
    "    S_path=np.transpose(np.array(s_vec))\n",
    "    return BM_path, S_path\n",
    "\n",
    "def jointime(T,path): \n",
    "    n_path, steps=path.shape\n",
    "    dt=T/(steps-1); \n",
    "    \n",
    "    times=np.arange(0,T,dt)\n",
    "    times=np.append(times,T); \n",
    "    times_vec=np.tile(times,[2,1]); \n",
    "    times_vec=np.transpose(times_vec)\n",
    "    times_vec=np.tile(times_vec,[n_path,1,1])\n",
    "    times_vec[:,:,1]=path\n",
    "    return times_vec\n",
    "\n",
    "def ComputeMultiLevelSig(path, number_of_segment, depth):\n",
    "    n_batch, nsteps,n_path = path.shape\n",
    "    t_vec = np.arange(0, nsteps-1, int(nsteps / number_of_segment))\n",
    "    t_vec = np.append(t_vec, nsteps-1)\n",
    "    MultiLevelSig = []\n",
    "    \n",
    "   # path_class=signatory.Path(path,depth);\n",
    "    ll=iisig.sig(np.expand_dims(path[:,0,:],axis=1),depth)\n",
    "    MultiLevelSig.append(ll)\n",
    "    \n",
    "    for i in range(len(t_vec)-1):    \n",
    "        ## Notice that we only use the signature of the concatenation of time and space.\n",
    "        MultiLevelSig.append(iisig.sig(path[:,0:t_vec[i+1]+1,:],depth)) ##if not\n",
    "        #MultiLevelSig.append(path_class.signature(t_vec[i],t_vec[i+1]+1))\n",
    "    MultiLevelSig=np.stack(MultiLevelSig)  \n",
    "    MultiLevelSig=rearrange(MultiLevelSig, 'b c h -> c b h') \n",
    "    return MultiLevelSig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab39edd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(batch_in=100):\n",
    "    dW = np.sqrt(dt)*np.random.normal(size=(batch_in, steps))\n",
    "    pth2=create_stock2(x0,r,sigma,T,steps,batch_in,dW)\n",
    "    BM_timePath=jointime(T,pth2[0]); \n",
    "    S_timePath=jointime(T,pth2[1]);\n",
    "    sigs=ComputeMultiLevelSig(S_timePath, 20, 3)\n",
    "    selection = np.linspace(0,steps, segs+1, dtype = np.int)\n",
    "\n",
    "    BM_seg=BM_timePath[:,selection,1]\n",
    "    dW=BM_seg[:,1:]-BM_seg[:,:-1]\n",
    "    dW=np.expand_dims(dW,axis=2)\n",
    "\n",
    "    dW=torch.tensor(dW,dtype=torch.float32)\n",
    "    sigs=torch.tensor(sigs,dtype=torch.float32)\n",
    "\n",
    "    ss=S_timePath[:,:,1]\n",
    "    YT=ss[:,-1]-np.min(ss,axis=1)\n",
    "    YT=torch.tensor(YT,dtype=torch.float32)\n",
    "    YT=YT.unsqueeze(axis=1)\n",
    "    return sigs, dW, YT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f77b47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lookback_PPDE(nn.Module):\n",
    "    def __init__(self): \n",
    "        super(Lookback_PPDE,self).__init__()\n",
    "        self.Y0=Parameter(torch.rand(100,1))\n",
    "        self.model=RNN2(input_size=14, output_size=1, hidden_size=128, num_layers=2)\n",
    "             \n",
    "    def forward(self,batch_sig,batch_dW): \n",
    "        Z_path=self.model(batch_sig)\n",
    "        Y=self.Y0\n",
    "        for i in range(segs):\n",
    "            Y=Y+Y*r*T/segs+sigma*Z_path[:,i,:]*batch_dW[:,i,:]\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1b6a574c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    n_layer = 4\n",
    "    batch_size = 1024\n",
    "    valid_size = 1024\n",
    "    \n",
    "    dim=14; \n",
    "    Ntime=20; \n",
    "    delta=1/Ntime\n",
    "    sqrt_deltaT=np.sqrt(1.0/Ntime); \n",
    "    lam=1; \n",
    "\n",
    "    logging_frequency = 100\n",
    "    verbose = True\n",
    "    y_init_range = [0, 1]\n",
    "    \n",
    "    num_hiddens = [dim,128,64,1] ## 256 ,256\n",
    "    \n",
    "def get_config(name):\n",
    "    try:\n",
    "        return globals()[name]\n",
    "    except KeyError:\n",
    "        raise KeyError(\"config not defined.\")\n",
    "\n",
    "cfg=get_config('Config')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a01f2643",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(nn.Module): \n",
    "    def __init__(self,cin, cout, batch_norm=False, activate=True): \n",
    "        super(Dense,self).__init__()\n",
    "        self.cin=cin; \n",
    "        self.cout=cout; \n",
    "        self.activate=activate; \n",
    "        \n",
    "        self.linear=nn.Linear(self.cin,self.cout) #The linear layer\n",
    "        #BatchNorm1d: it requires the input to be a correct size\n",
    "        if batch_norm: \n",
    "            self.bn=nn.BatchNorm1d(cout,eps=EPSILON,momentum=MOMENTUM)\n",
    "        else: \n",
    "            self.bn=None\n",
    "      #  nn.init.normal_(self.linear.weight,std=5.0/np.sqrt(cin+cout))\n",
    "        # This is the He initialization\n",
    "        \n",
    "    def forward(self,x): \n",
    "        x=self.linear(x)\n",
    "        if self.bn is not None:\n",
    "            x=self.bn(x)\n",
    "        if self.activate:\n",
    "            x=torch.tanh(x)\n",
    "        return x \n",
    "    \n",
    "class FFN(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(FFN,self).__init__()\n",
    "        self.config=config\n",
    "        \n",
    "        self.bn=nn.BatchNorm1d(config.num_hiddens[0],eps=EPSILON,momentum=MOMENTUM) ## So there is batch norm no problem\n",
    "        # range(1,5): 1,2,3,4\n",
    "        self.layers=[Dense(config.num_hiddens[i-1],config.num_hiddens[i]) for i in range(1, len(config.num_hiddens)-1)]\n",
    "        self.layers+=[Dense(config.num_hiddens[-2], config.num_hiddens[-1],activate=False)]\n",
    "        self.layers=nn.Sequential(*self.layers)\n",
    "    \n",
    "    def forward(self,x):\n",
    "      #  x=self.bn(x)\n",
    "        x=self.layers(x)\n",
    "        return x \n",
    "    \n",
    "class Lookback_PPDE(nn.Module):\n",
    "    def __init__(self,cfg): \n",
    "        super(Lookback_PPDE,self).__init__()\n",
    "        self.cfg=cfg\n",
    "        self.Ntime=self.cfg.Ntime \n",
    "    #    self.Y0=Parameter(torch.tensor([0.0])) #torch.rand(500,1)\n",
    "        self.Y0=Parameter(torch.rand(100,1))\n",
    "        self.mList=nn.ModuleList([FFN(self.cfg) for _ in range(self.Ntime)])\n",
    "        \n",
    "    def forward(self,batch_sig,batch_dW): \n",
    "   #     Z_path=self.model(batch_sig)\n",
    "        Y=self.Y0\n",
    "        for i in range(segs):\n",
    "            Y=Y+Y*r*T/segs+sigma*self.mList[i](batch_sig[:,i,:])*batch_dW[:,i,:]\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3fb3afe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Loss(Y_pred,Y_true):\n",
    "    res=torch.mean((Y_pred-Y_true)**2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d84ce302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.nn import Parameter\n",
    "import math\n",
    "model_PPDE=Lookback_PPDE(cfg)\n",
    "optimizer=optim.Adam(model_PPDE.parameters(),lr=1e-3)\n",
    "epochs=400 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "460db5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(batch_in=100):\n",
    "    dW = np.sqrt(dt)*np.random.normal(size=(batch_in, steps))\n",
    "    pth2=create_stock2(x0,r,sigma,T,steps,batch_in,dW)\n",
    "    BM_timePath=jointime(T,pth2[0]); \n",
    "    S_timePath=jointime(T,pth2[1]);\n",
    "    sigs=ComputeMultiLevelSig(S_timePath, 20, 3)\n",
    "    selection = np.linspace(0,steps, segs+1, dtype = np.int)\n",
    "\n",
    "    BM_seg=BM_timePath[:,selection,1]\n",
    "    dW=BM_seg[:,1:]-BM_seg[:,:-1]\n",
    "    dW=np.expand_dims(dW,axis=2)\n",
    "\n",
    "    dW=torch.tensor(dW,dtype=torch.float32)\n",
    "    sigs=torch.tensor(sigs,dtype=torch.float32)\n",
    "\n",
    "    ss=S_timePath[:,:,1]\n",
    "    YT=ss[:,-1]-np.min(ss,axis=1)\n",
    "    YT=torch.tensor(YT,dtype=torch.float32)\n",
    "    YT=YT.unsqueeze(axis=1)\n",
    "    return sigs, dW, YT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9e5ad621",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_PPDE=Lookback_PPDE(cfg)\n",
    "model_PPDE\n",
    "optimizer=optim.Adam(model_PPDE.parameters(),lr=2e-3)\n",
    "grad_clip=0.2\n",
    "y0_mean=[];\n",
    "loss_vec=[];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5d409a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0 tensor(0.4824, grad_fn=<MeanBackward0>) tensor(1.5609, grad_fn=<MeanBackward0>)\n",
      "Iter: 10 tensor(0.4820, grad_fn=<MeanBackward0>) tensor(1.1977, grad_fn=<MeanBackward0>)\n",
      "Iter: 20 tensor(0.4848, grad_fn=<MeanBackward0>) tensor(0.1789, grad_fn=<MeanBackward0>)\n",
      "Iter: 30 tensor(0.4880, grad_fn=<MeanBackward0>) tensor(0.1655, grad_fn=<MeanBackward0>)\n",
      "Iter: 40 tensor(0.4913, grad_fn=<MeanBackward0>) tensor(0.1193, grad_fn=<MeanBackward0>)\n",
      "Iter: 50 tensor(0.4945, grad_fn=<MeanBackward0>) tensor(0.1322, grad_fn=<MeanBackward0>)\n",
      "Iter: 60 tensor(0.4979, grad_fn=<MeanBackward0>) tensor(0.1365, grad_fn=<MeanBackward0>)\n",
      "Iter: 70 tensor(0.5011, grad_fn=<MeanBackward0>) tensor(0.1083, grad_fn=<MeanBackward0>)\n",
      "Iter: 80 tensor(0.5041, grad_fn=<MeanBackward0>) tensor(0.0927, grad_fn=<MeanBackward0>)\n",
      "Iter: 90 tensor(0.5070, grad_fn=<MeanBackward0>) tensor(0.1731, grad_fn=<MeanBackward0>)\n",
      "Iter: 100 tensor(0.5095, grad_fn=<MeanBackward0>) tensor(0.0939, grad_fn=<MeanBackward0>)\n",
      "Iter: 110 tensor(0.5120, grad_fn=<MeanBackward0>) tensor(0.0961, grad_fn=<MeanBackward0>)\n",
      "Iter: 120 tensor(0.5142, grad_fn=<MeanBackward0>) tensor(0.1008, grad_fn=<MeanBackward0>)\n",
      "Iter: 130 tensor(0.5168, grad_fn=<MeanBackward0>) tensor(0.1059, grad_fn=<MeanBackward0>)\n",
      "Iter: 140 tensor(0.5193, grad_fn=<MeanBackward0>) tensor(0.0694, grad_fn=<MeanBackward0>)\n",
      "Iter: 150 tensor(0.5221, grad_fn=<MeanBackward0>) tensor(0.1439, grad_fn=<MeanBackward0>)\n",
      "Iter: 160 tensor(0.5249, grad_fn=<MeanBackward0>) tensor(0.1159, grad_fn=<MeanBackward0>)\n",
      "Iter: 170 tensor(0.5270, grad_fn=<MeanBackward0>) tensor(0.1073, grad_fn=<MeanBackward0>)\n",
      "Iter: 180 tensor(0.5288, grad_fn=<MeanBackward0>) tensor(0.0729, grad_fn=<MeanBackward0>)\n",
      "Iter: 190 tensor(0.5305, grad_fn=<MeanBackward0>) tensor(0.0636, grad_fn=<MeanBackward0>)\n",
      "Iter: 200 tensor(0.5320, grad_fn=<MeanBackward0>) tensor(0.0617, grad_fn=<MeanBackward0>)\n",
      "Iter: 210 tensor(0.5340, grad_fn=<MeanBackward0>) tensor(0.0805, grad_fn=<MeanBackward0>)\n",
      "Iter: 220 tensor(0.5363, grad_fn=<MeanBackward0>) tensor(0.2182, grad_fn=<MeanBackward0>)\n",
      "Iter: 230 tensor(0.5382, grad_fn=<MeanBackward0>) tensor(0.0690, grad_fn=<MeanBackward0>)\n",
      "Iter: 240 tensor(0.5399, grad_fn=<MeanBackward0>) tensor(0.1012, grad_fn=<MeanBackward0>)\n",
      "Iter: 250 tensor(0.5415, grad_fn=<MeanBackward0>) tensor(0.0647, grad_fn=<MeanBackward0>)\n",
      "Iter: 260 tensor(0.5429, grad_fn=<MeanBackward0>) tensor(0.0427, grad_fn=<MeanBackward0>)\n",
      "Iter: 270 tensor(0.5447, grad_fn=<MeanBackward0>) tensor(0.0977, grad_fn=<MeanBackward0>)\n",
      "Iter: 280 tensor(0.5470, grad_fn=<MeanBackward0>) tensor(0.0560, grad_fn=<MeanBackward0>)\n",
      "Iter: 290 tensor(0.5489, grad_fn=<MeanBackward0>) tensor(0.1082, grad_fn=<MeanBackward0>)\n",
      "Iter: 300 tensor(0.5503, grad_fn=<MeanBackward0>) tensor(0.3475, grad_fn=<MeanBackward0>)\n",
      "Iter: 310 tensor(0.5514, grad_fn=<MeanBackward0>) tensor(0.0933, grad_fn=<MeanBackward0>)\n",
      "Iter: 320 tensor(0.5527, grad_fn=<MeanBackward0>) tensor(0.0766, grad_fn=<MeanBackward0>)\n",
      "Iter: 330 tensor(0.5537, grad_fn=<MeanBackward0>) tensor(0.0621, grad_fn=<MeanBackward0>)\n",
      "Iter: 340 tensor(0.5550, grad_fn=<MeanBackward0>) tensor(0.3446, grad_fn=<MeanBackward0>)\n",
      "Iter: 350 tensor(0.5563, grad_fn=<MeanBackward0>) tensor(0.0666, grad_fn=<MeanBackward0>)\n",
      "Iter: 360 tensor(0.5574, grad_fn=<MeanBackward0>) tensor(0.0632, grad_fn=<MeanBackward0>)\n",
      "Iter: 370 tensor(0.5586, grad_fn=<MeanBackward0>) tensor(0.0497, grad_fn=<MeanBackward0>)\n",
      "Iter: 380 tensor(0.5593, grad_fn=<MeanBackward0>) tensor(0.1450, grad_fn=<MeanBackward0>)\n",
      "Iter: 390 tensor(0.5599, grad_fn=<MeanBackward0>) tensor(0.0761, grad_fn=<MeanBackward0>)\n",
      "Iter: 400 tensor(0.5605, grad_fn=<MeanBackward0>) tensor(0.0418, grad_fn=<MeanBackward0>)\n",
      "Iter: 410 tensor(0.5613, grad_fn=<MeanBackward0>) tensor(0.0895, grad_fn=<MeanBackward0>)\n",
      "Iter: 420 tensor(0.5625, grad_fn=<MeanBackward0>) tensor(0.0534, grad_fn=<MeanBackward0>)\n",
      "Iter: 430 tensor(0.5636, grad_fn=<MeanBackward0>) tensor(0.0536, grad_fn=<MeanBackward0>)\n",
      "Iter: 440 tensor(0.5644, grad_fn=<MeanBackward0>) tensor(0.1182, grad_fn=<MeanBackward0>)\n",
      "Iter: 450 tensor(0.5652, grad_fn=<MeanBackward0>) tensor(0.0581, grad_fn=<MeanBackward0>)\n",
      "Iter: 460 tensor(0.5659, grad_fn=<MeanBackward0>) tensor(0.0413, grad_fn=<MeanBackward0>)\n",
      "Iter: 470 tensor(0.5671, grad_fn=<MeanBackward0>) tensor(0.0612, grad_fn=<MeanBackward0>)\n",
      "Iter: 480 tensor(0.5683, grad_fn=<MeanBackward0>) tensor(0.0937, grad_fn=<MeanBackward0>)\n",
      "Iter: 490 tensor(0.5693, grad_fn=<MeanBackward0>) tensor(0.0454, grad_fn=<MeanBackward0>)\n",
      "Iter: 500 tensor(0.5702, grad_fn=<MeanBackward0>) tensor(0.0791, grad_fn=<MeanBackward0>)\n",
      "Iter: 510 tensor(0.5705, grad_fn=<MeanBackward0>) tensor(0.0444, grad_fn=<MeanBackward0>)\n",
      "Iter: 520 tensor(0.5707, grad_fn=<MeanBackward0>) tensor(0.0495, grad_fn=<MeanBackward0>)\n",
      "Iter: 530 tensor(0.5708, grad_fn=<MeanBackward0>) tensor(0.0442, grad_fn=<MeanBackward0>)\n",
      "Iter: 540 tensor(0.5712, grad_fn=<MeanBackward0>) tensor(0.1124, grad_fn=<MeanBackward0>)\n",
      "Iter: 550 tensor(0.5716, grad_fn=<MeanBackward0>) tensor(0.0685, grad_fn=<MeanBackward0>)\n",
      "Iter: 560 tensor(0.5718, grad_fn=<MeanBackward0>) tensor(0.0478, grad_fn=<MeanBackward0>)\n",
      "Iter: 570 tensor(0.5720, grad_fn=<MeanBackward0>) tensor(0.0969, grad_fn=<MeanBackward0>)\n",
      "Iter: 580 tensor(0.5724, grad_fn=<MeanBackward0>) tensor(0.0580, grad_fn=<MeanBackward0>)\n",
      "Iter: 590 tensor(0.5725, grad_fn=<MeanBackward0>) tensor(0.1305, grad_fn=<MeanBackward0>)\n",
      "Iter: 600 tensor(0.5732, grad_fn=<MeanBackward0>) tensor(0.0956, grad_fn=<MeanBackward0>)\n",
      "Iter: 610 tensor(0.5741, grad_fn=<MeanBackward0>) tensor(0.0959, grad_fn=<MeanBackward0>)\n",
      "Iter: 620 tensor(0.5750, grad_fn=<MeanBackward0>) tensor(0.1364, grad_fn=<MeanBackward0>)\n",
      "Iter: 630 tensor(0.5755, grad_fn=<MeanBackward0>) tensor(0.1351, grad_fn=<MeanBackward0>)\n",
      "Iter: 640 tensor(0.5757, grad_fn=<MeanBackward0>) tensor(0.1118, grad_fn=<MeanBackward0>)\n",
      "Iter: 650 tensor(0.5757, grad_fn=<MeanBackward0>) tensor(0.0400, grad_fn=<MeanBackward0>)\n",
      "Iter: 660 tensor(0.5760, grad_fn=<MeanBackward0>) tensor(0.0513, grad_fn=<MeanBackward0>)\n",
      "Iter: 670 tensor(0.5768, grad_fn=<MeanBackward0>) tensor(0.1593, grad_fn=<MeanBackward0>)\n",
      "Iter: 680 tensor(0.5773, grad_fn=<MeanBackward0>) tensor(0.0519, grad_fn=<MeanBackward0>)\n",
      "Iter: 690 tensor(0.5774, grad_fn=<MeanBackward0>) tensor(0.0545, grad_fn=<MeanBackward0>)\n",
      "Iter: 700 tensor(0.5776, grad_fn=<MeanBackward0>) tensor(0.0654, grad_fn=<MeanBackward0>)\n",
      "Iter: 710 tensor(0.5784, grad_fn=<MeanBackward0>) tensor(0.0684, grad_fn=<MeanBackward0>)\n",
      "Iter: 720 tensor(0.5787, grad_fn=<MeanBackward0>) tensor(0.0509, grad_fn=<MeanBackward0>)\n",
      "Iter: 730 tensor(0.5786, grad_fn=<MeanBackward0>) tensor(0.2674, grad_fn=<MeanBackward0>)\n",
      "Iter: 740 tensor(0.5788, grad_fn=<MeanBackward0>) tensor(0.0922, grad_fn=<MeanBackward0>)\n",
      "Iter: 750 tensor(0.5785, grad_fn=<MeanBackward0>) tensor(0.0415, grad_fn=<MeanBackward0>)\n",
      "Iter: 760 tensor(0.5783, grad_fn=<MeanBackward0>) tensor(0.0477, grad_fn=<MeanBackward0>)\n",
      "Iter: 770 tensor(0.5779, grad_fn=<MeanBackward0>) tensor(0.0834, grad_fn=<MeanBackward0>)\n",
      "Iter: 780 tensor(0.5781, grad_fn=<MeanBackward0>) tensor(0.0586, grad_fn=<MeanBackward0>)\n",
      "Iter: 790 tensor(0.5780, grad_fn=<MeanBackward0>) tensor(0.0758, grad_fn=<MeanBackward0>)\n",
      "Iter: 800 tensor(0.5774, grad_fn=<MeanBackward0>) tensor(0.0591, grad_fn=<MeanBackward0>)\n",
      "Iter: 810 tensor(0.5773, grad_fn=<MeanBackward0>) tensor(0.0550, grad_fn=<MeanBackward0>)\n",
      "Iter: 820 tensor(0.5777, grad_fn=<MeanBackward0>) tensor(0.0596, grad_fn=<MeanBackward0>)\n",
      "Iter: 830 tensor(0.5776, grad_fn=<MeanBackward0>) tensor(0.0645, grad_fn=<MeanBackward0>)\n",
      "Iter: 840 tensor(0.5774, grad_fn=<MeanBackward0>) tensor(0.0468, grad_fn=<MeanBackward0>)\n",
      "Iter: 850 tensor(0.5773, grad_fn=<MeanBackward0>) tensor(0.2794, grad_fn=<MeanBackward0>)\n",
      "Iter: 860 tensor(0.5775, grad_fn=<MeanBackward0>) tensor(0.0635, grad_fn=<MeanBackward0>)\n",
      "Iter: 870 tensor(0.5771, grad_fn=<MeanBackward0>) tensor(0.0353, grad_fn=<MeanBackward0>)\n",
      "Iter: 880 tensor(0.5766, grad_fn=<MeanBackward0>) tensor(0.0774, grad_fn=<MeanBackward0>)\n",
      "Iter: 890 tensor(0.5766, grad_fn=<MeanBackward0>) tensor(0.0862, grad_fn=<MeanBackward0>)\n",
      "Iter: 900 tensor(0.5772, grad_fn=<MeanBackward0>) tensor(0.1063, grad_fn=<MeanBackward0>)\n",
      "Iter: 910 tensor(0.5775, grad_fn=<MeanBackward0>) tensor(0.0738, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 920 tensor(0.5774, grad_fn=<MeanBackward0>) tensor(0.0654, grad_fn=<MeanBackward0>)\n",
      "Iter: 930 tensor(0.5771, grad_fn=<MeanBackward0>) tensor(0.0735, grad_fn=<MeanBackward0>)\n",
      "Iter: 940 tensor(0.5768, grad_fn=<MeanBackward0>) tensor(0.1002, grad_fn=<MeanBackward0>)\n",
      "Iter: 950 tensor(0.5768, grad_fn=<MeanBackward0>) tensor(0.0447, grad_fn=<MeanBackward0>)\n",
      "Iter: 960 tensor(0.5774, grad_fn=<MeanBackward0>) tensor(0.9063, grad_fn=<MeanBackward0>)\n",
      "Iter: 970 tensor(0.5775, grad_fn=<MeanBackward0>) tensor(0.0629, grad_fn=<MeanBackward0>)\n",
      "Iter: 980 tensor(0.5775, grad_fn=<MeanBackward0>) tensor(0.0738, grad_fn=<MeanBackward0>)\n",
      "Iter: 990 tensor(0.5772, grad_fn=<MeanBackward0>) tensor(0.0421, grad_fn=<MeanBackward0>)\n",
      "Iter: 1000 tensor(0.5768, grad_fn=<MeanBackward0>) tensor(0.3633, grad_fn=<MeanBackward0>)\n",
      "Iter: 1010 tensor(0.5772, grad_fn=<MeanBackward0>) tensor(0.0952, grad_fn=<MeanBackward0>)\n",
      "Iter: 1020 tensor(0.5775, grad_fn=<MeanBackward0>) tensor(0.0883, grad_fn=<MeanBackward0>)\n",
      "Iter: 1030 tensor(0.5777, grad_fn=<MeanBackward0>) tensor(0.1329, grad_fn=<MeanBackward0>)\n",
      "Iter: 1040 tensor(0.5779, grad_fn=<MeanBackward0>) tensor(0.0482, grad_fn=<MeanBackward0>)\n",
      "Iter: 1050 tensor(0.5782, grad_fn=<MeanBackward0>) tensor(0.0607, grad_fn=<MeanBackward0>)\n",
      "Iter: 1060 tensor(0.5785, grad_fn=<MeanBackward0>) tensor(0.0630, grad_fn=<MeanBackward0>)\n",
      "Iter: 1070 tensor(0.5783, grad_fn=<MeanBackward0>) tensor(0.0589, grad_fn=<MeanBackward0>)\n",
      "Iter: 1080 tensor(0.5784, grad_fn=<MeanBackward0>) tensor(0.0353, grad_fn=<MeanBackward0>)\n",
      "Iter: 1090 tensor(0.5791, grad_fn=<MeanBackward0>) tensor(0.0841, grad_fn=<MeanBackward0>)\n",
      "Iter: 1100 tensor(0.5795, grad_fn=<MeanBackward0>) tensor(0.5978, grad_fn=<MeanBackward0>)\n",
      "Iter: 1110 tensor(0.5802, grad_fn=<MeanBackward0>) tensor(0.3661, grad_fn=<MeanBackward0>)\n",
      "Iter: 1120 tensor(0.5807, grad_fn=<MeanBackward0>) tensor(0.1582, grad_fn=<MeanBackward0>)\n",
      "Iter: 1130 tensor(0.5806, grad_fn=<MeanBackward0>) tensor(0.0458, grad_fn=<MeanBackward0>)\n",
      "Iter: 1140 tensor(0.5800, grad_fn=<MeanBackward0>) tensor(0.0468, grad_fn=<MeanBackward0>)\n",
      "Iter: 1150 tensor(0.5797, grad_fn=<MeanBackward0>) tensor(0.0655, grad_fn=<MeanBackward0>)\n",
      "Iter: 1160 tensor(0.5796, grad_fn=<MeanBackward0>) tensor(0.0518, grad_fn=<MeanBackward0>)\n",
      "Iter: 1170 tensor(0.5797, grad_fn=<MeanBackward0>) tensor(0.0563, grad_fn=<MeanBackward0>)\n",
      "Iter: 1180 tensor(0.5799, grad_fn=<MeanBackward0>) tensor(0.0766, grad_fn=<MeanBackward0>)\n",
      "Iter: 1190 tensor(0.5800, grad_fn=<MeanBackward0>) tensor(0.0610, grad_fn=<MeanBackward0>)\n",
      "Iter: 1200 tensor(0.5801, grad_fn=<MeanBackward0>) tensor(0.0611, grad_fn=<MeanBackward0>)\n",
      "Iter: 1210 tensor(0.5804, grad_fn=<MeanBackward0>) tensor(0.0389, grad_fn=<MeanBackward0>)\n",
      "Iter: 1220 tensor(0.5807, grad_fn=<MeanBackward0>) tensor(0.0576, grad_fn=<MeanBackward0>)\n",
      "Iter: 1230 tensor(0.5807, grad_fn=<MeanBackward0>) tensor(0.0407, grad_fn=<MeanBackward0>)\n",
      "Iter: 1240 tensor(0.5803, grad_fn=<MeanBackward0>) tensor(0.0394, grad_fn=<MeanBackward0>)\n",
      "Iter: 1250 tensor(0.5799, grad_fn=<MeanBackward0>) tensor(0.0808, grad_fn=<MeanBackward0>)\n",
      "Iter: 1260 tensor(0.5795, grad_fn=<MeanBackward0>) tensor(0.0430, grad_fn=<MeanBackward0>)\n",
      "Iter: 1270 tensor(0.5794, grad_fn=<MeanBackward0>) tensor(0.0727, grad_fn=<MeanBackward0>)\n",
      "Iter: 1280 tensor(0.5793, grad_fn=<MeanBackward0>) tensor(0.0543, grad_fn=<MeanBackward0>)\n",
      "Iter: 1290 tensor(0.5789, grad_fn=<MeanBackward0>) tensor(0.0553, grad_fn=<MeanBackward0>)\n",
      "Iter: 1300 tensor(0.5787, grad_fn=<MeanBackward0>) tensor(0.0725, grad_fn=<MeanBackward0>)\n",
      "Iter: 1310 tensor(0.5790, grad_fn=<MeanBackward0>) tensor(0.0526, grad_fn=<MeanBackward0>)\n",
      "Iter: 1320 tensor(0.5793, grad_fn=<MeanBackward0>) tensor(0.0395, grad_fn=<MeanBackward0>)\n",
      "Iter: 1330 tensor(0.5787, grad_fn=<MeanBackward0>) tensor(0.0717, grad_fn=<MeanBackward0>)\n",
      "Iter: 1340 tensor(0.5784, grad_fn=<MeanBackward0>) tensor(0.0776, grad_fn=<MeanBackward0>)\n",
      "Iter: 1350 tensor(0.5787, grad_fn=<MeanBackward0>) tensor(0.0411, grad_fn=<MeanBackward0>)\n",
      "Iter: 1360 tensor(0.5790, grad_fn=<MeanBackward0>) tensor(0.0764, grad_fn=<MeanBackward0>)\n",
      "Iter: 1370 tensor(0.5794, grad_fn=<MeanBackward0>) tensor(0.0876, grad_fn=<MeanBackward0>)\n",
      "Iter: 1380 tensor(0.5797, grad_fn=<MeanBackward0>) tensor(0.0992, grad_fn=<MeanBackward0>)\n",
      "Iter: 1390 tensor(0.5795, grad_fn=<MeanBackward0>) tensor(0.0532, grad_fn=<MeanBackward0>)\n",
      "Iter: 1400 tensor(0.5792, grad_fn=<MeanBackward0>) tensor(0.2245, grad_fn=<MeanBackward0>)\n",
      "Iter: 1410 tensor(0.5790, grad_fn=<MeanBackward0>) tensor(0.0462, grad_fn=<MeanBackward0>)\n",
      "Iter: 1420 tensor(0.5789, grad_fn=<MeanBackward0>) tensor(0.0445, grad_fn=<MeanBackward0>)\n",
      "Iter: 1430 tensor(0.5787, grad_fn=<MeanBackward0>) tensor(0.0566, grad_fn=<MeanBackward0>)\n",
      "Iter: 1440 tensor(0.5790, grad_fn=<MeanBackward0>) tensor(0.0427, grad_fn=<MeanBackward0>)\n",
      "Iter: 1450 tensor(0.5793, grad_fn=<MeanBackward0>) tensor(0.0488, grad_fn=<MeanBackward0>)\n",
      "Iter: 1460 tensor(0.5794, grad_fn=<MeanBackward0>) tensor(0.0565, grad_fn=<MeanBackward0>)\n",
      "Iter: 1470 tensor(0.5792, grad_fn=<MeanBackward0>) tensor(0.0452, grad_fn=<MeanBackward0>)\n",
      "Iter: 1480 tensor(0.5793, grad_fn=<MeanBackward0>) tensor(0.0542, grad_fn=<MeanBackward0>)\n",
      "Iter: 1490 tensor(0.5793, grad_fn=<MeanBackward0>) tensor(0.0582, grad_fn=<MeanBackward0>)\n",
      "Iter: 1500 tensor(0.5788, grad_fn=<MeanBackward0>) tensor(0.0428, grad_fn=<MeanBackward0>)\n",
      "Iter: 1510 tensor(0.5781, grad_fn=<MeanBackward0>) tensor(0.0619, grad_fn=<MeanBackward0>)\n",
      "Iter: 1520 tensor(0.5778, grad_fn=<MeanBackward0>) tensor(0.0711, grad_fn=<MeanBackward0>)\n",
      "Iter: 1530 tensor(0.5778, grad_fn=<MeanBackward0>) tensor(0.0284, grad_fn=<MeanBackward0>)\n",
      "Iter: 1540 tensor(0.5774, grad_fn=<MeanBackward0>) tensor(0.0277, grad_fn=<MeanBackward0>)\n",
      "Iter: 1550 tensor(0.5769, grad_fn=<MeanBackward0>) tensor(0.1270, grad_fn=<MeanBackward0>)\n",
      "Iter: 1560 tensor(0.5768, grad_fn=<MeanBackward0>) tensor(0.0483, grad_fn=<MeanBackward0>)\n",
      "Iter: 1570 tensor(0.5771, grad_fn=<MeanBackward0>) tensor(0.0595, grad_fn=<MeanBackward0>)\n",
      "Iter: 1580 tensor(0.5777, grad_fn=<MeanBackward0>) tensor(0.0731, grad_fn=<MeanBackward0>)\n",
      "Iter: 1590 tensor(0.5781, grad_fn=<MeanBackward0>) tensor(0.0795, grad_fn=<MeanBackward0>)\n",
      "Iter: 1600 tensor(0.5782, grad_fn=<MeanBackward0>) tensor(0.0502, grad_fn=<MeanBackward0>)\n",
      "Iter: 1610 tensor(0.5783, grad_fn=<MeanBackward0>) tensor(0.0789, grad_fn=<MeanBackward0>)\n",
      "Iter: 1620 tensor(0.5787, grad_fn=<MeanBackward0>) tensor(0.0524, grad_fn=<MeanBackward0>)\n",
      "Iter: 1630 tensor(0.5788, grad_fn=<MeanBackward0>) tensor(0.0643, grad_fn=<MeanBackward0>)\n",
      "Iter: 1640 tensor(0.5788, grad_fn=<MeanBackward0>) tensor(0.0821, grad_fn=<MeanBackward0>)\n",
      "Iter: 1650 tensor(0.5788, grad_fn=<MeanBackward0>) tensor(0.0513, grad_fn=<MeanBackward0>)\n",
      "Iter: 1660 tensor(0.5784, grad_fn=<MeanBackward0>) tensor(0.1135, grad_fn=<MeanBackward0>)\n",
      "Iter: 1670 tensor(0.5783, grad_fn=<MeanBackward0>) tensor(0.0431, grad_fn=<MeanBackward0>)\n",
      "Iter: 1680 tensor(0.5782, grad_fn=<MeanBackward0>) tensor(0.1235, grad_fn=<MeanBackward0>)\n",
      "Iter: 1690 tensor(0.5785, grad_fn=<MeanBackward0>) tensor(0.0774, grad_fn=<MeanBackward0>)\n",
      "Iter: 1700 tensor(0.5786, grad_fn=<MeanBackward0>) tensor(0.0989, grad_fn=<MeanBackward0>)\n",
      "Iter: 1710 tensor(0.5789, grad_fn=<MeanBackward0>) tensor(0.2791, grad_fn=<MeanBackward0>)\n",
      "Iter: 1720 tensor(0.5792, grad_fn=<MeanBackward0>) tensor(0.0547, grad_fn=<MeanBackward0>)\n",
      "Iter: 1730 tensor(0.5791, grad_fn=<MeanBackward0>) tensor(0.0467, grad_fn=<MeanBackward0>)\n",
      "Iter: 1740 tensor(0.5792, grad_fn=<MeanBackward0>) tensor(0.0727, grad_fn=<MeanBackward0>)\n",
      "Iter: 1750 tensor(0.5793, grad_fn=<MeanBackward0>) tensor(0.0498, grad_fn=<MeanBackward0>)\n",
      "Iter: 1760 tensor(0.5801, grad_fn=<MeanBackward0>) tensor(0.2240, grad_fn=<MeanBackward0>)\n",
      "Iter: 1770 tensor(0.5810, grad_fn=<MeanBackward0>) tensor(0.0957, grad_fn=<MeanBackward0>)\n",
      "Iter: 1780 tensor(0.5814, grad_fn=<MeanBackward0>) tensor(0.0741, grad_fn=<MeanBackward0>)\n",
      "Iter: 1790 tensor(0.5815, grad_fn=<MeanBackward0>) tensor(0.0629, grad_fn=<MeanBackward0>)\n",
      "Iter: 1800 tensor(0.5817, grad_fn=<MeanBackward0>) tensor(0.0771, grad_fn=<MeanBackward0>)\n",
      "Iter: 1810 tensor(0.5821, grad_fn=<MeanBackward0>) tensor(0.0651, grad_fn=<MeanBackward0>)\n",
      "Iter: 1820 tensor(0.5822, grad_fn=<MeanBackward0>) tensor(0.0569, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1830 tensor(0.5817, grad_fn=<MeanBackward0>) tensor(0.1058, grad_fn=<MeanBackward0>)\n",
      "Iter: 1840 tensor(0.5818, grad_fn=<MeanBackward0>) tensor(0.1070, grad_fn=<MeanBackward0>)\n",
      "Iter: 1850 tensor(0.5814, grad_fn=<MeanBackward0>) tensor(0.1083, grad_fn=<MeanBackward0>)\n",
      "Iter: 1860 tensor(0.5809, grad_fn=<MeanBackward0>) tensor(0.0914, grad_fn=<MeanBackward0>)\n",
      "Iter: 1870 tensor(0.5806, grad_fn=<MeanBackward0>) tensor(0.0631, grad_fn=<MeanBackward0>)\n",
      "Iter: 1880 tensor(0.5801, grad_fn=<MeanBackward0>) tensor(0.7190, grad_fn=<MeanBackward0>)\n",
      "Iter: 1890 tensor(0.5806, grad_fn=<MeanBackward0>) tensor(0.0412, grad_fn=<MeanBackward0>)\n",
      "Iter: 1900 tensor(0.5816, grad_fn=<MeanBackward0>) tensor(0.1014, grad_fn=<MeanBackward0>)\n",
      "Iter: 1910 tensor(0.5822, grad_fn=<MeanBackward0>) tensor(0.1031, grad_fn=<MeanBackward0>)\n",
      "Iter: 1920 tensor(0.5830, grad_fn=<MeanBackward0>) tensor(0.1147, grad_fn=<MeanBackward0>)\n",
      "Iter: 1930 tensor(0.5841, grad_fn=<MeanBackward0>) tensor(0.1739, grad_fn=<MeanBackward0>)\n",
      "Iter: 1940 tensor(0.5848, grad_fn=<MeanBackward0>) tensor(0.1029, grad_fn=<MeanBackward0>)\n",
      "Iter: 1950 tensor(0.5850, grad_fn=<MeanBackward0>) tensor(0.0546, grad_fn=<MeanBackward0>)\n",
      "Iter: 1960 tensor(0.5848, grad_fn=<MeanBackward0>) tensor(0.0857, grad_fn=<MeanBackward0>)\n",
      "Iter: 1970 tensor(0.5841, grad_fn=<MeanBackward0>) tensor(0.0847, grad_fn=<MeanBackward0>)\n",
      "Iter: 1980 tensor(0.5834, grad_fn=<MeanBackward0>) tensor(0.0773, grad_fn=<MeanBackward0>)\n",
      "Iter: 1990 tensor(0.5827, grad_fn=<MeanBackward0>) tensor(0.0732, grad_fn=<MeanBackward0>)\n",
      "Iter: 2000 tensor(0.5825, grad_fn=<MeanBackward0>) tensor(0.1227, grad_fn=<MeanBackward0>)\n",
      "Iter: 2010 tensor(0.5826, grad_fn=<MeanBackward0>) tensor(0.0485, grad_fn=<MeanBackward0>)\n",
      "Iter: 2020 tensor(0.5825, grad_fn=<MeanBackward0>) tensor(0.1038, grad_fn=<MeanBackward0>)\n",
      "Iter: 2030 tensor(0.5819, grad_fn=<MeanBackward0>) tensor(0.0409, grad_fn=<MeanBackward0>)\n",
      "Iter: 2040 tensor(0.5812, grad_fn=<MeanBackward0>) tensor(0.2213, grad_fn=<MeanBackward0>)\n",
      "Iter: 2050 tensor(0.5811, grad_fn=<MeanBackward0>) tensor(0.0542, grad_fn=<MeanBackward0>)\n",
      "Iter: 2060 tensor(0.5810, grad_fn=<MeanBackward0>) tensor(0.0519, grad_fn=<MeanBackward0>)\n",
      "Iter: 2070 tensor(0.5809, grad_fn=<MeanBackward0>) tensor(0.0686, grad_fn=<MeanBackward0>)\n",
      "Iter: 2080 tensor(0.5810, grad_fn=<MeanBackward0>) tensor(0.1029, grad_fn=<MeanBackward0>)\n",
      "Iter: 2090 tensor(0.5809, grad_fn=<MeanBackward0>) tensor(0.1343, grad_fn=<MeanBackward0>)\n",
      "Iter: 2100 tensor(0.5810, grad_fn=<MeanBackward0>) tensor(0.0996, grad_fn=<MeanBackward0>)\n",
      "Iter: 2110 tensor(0.5813, grad_fn=<MeanBackward0>) tensor(0.0744, grad_fn=<MeanBackward0>)\n",
      "Iter: 2120 tensor(0.5813, grad_fn=<MeanBackward0>) tensor(0.1317, grad_fn=<MeanBackward0>)\n",
      "Iter: 2130 tensor(0.5811, grad_fn=<MeanBackward0>) tensor(0.1217, grad_fn=<MeanBackward0>)\n",
      "Iter: 2140 tensor(0.5814, grad_fn=<MeanBackward0>) tensor(0.0590, grad_fn=<MeanBackward0>)\n",
      "Iter: 2150 tensor(0.5817, grad_fn=<MeanBackward0>) tensor(0.0739, grad_fn=<MeanBackward0>)\n",
      "Iter: 2160 tensor(0.5817, grad_fn=<MeanBackward0>) tensor(0.0370, grad_fn=<MeanBackward0>)\n",
      "Iter: 2170 tensor(0.5816, grad_fn=<MeanBackward0>) tensor(0.0519, grad_fn=<MeanBackward0>)\n",
      "Iter: 2180 tensor(0.5816, grad_fn=<MeanBackward0>) tensor(0.0653, grad_fn=<MeanBackward0>)\n",
      "Iter: 2190 tensor(0.5815, grad_fn=<MeanBackward0>) tensor(0.0794, grad_fn=<MeanBackward0>)\n",
      "Iter: 2200 tensor(0.5816, grad_fn=<MeanBackward0>) tensor(0.0590, grad_fn=<MeanBackward0>)\n",
      "Iter: 2210 tensor(0.5815, grad_fn=<MeanBackward0>) tensor(0.1073, grad_fn=<MeanBackward0>)\n",
      "Iter: 2220 tensor(0.5816, grad_fn=<MeanBackward0>) tensor(0.0741, grad_fn=<MeanBackward0>)\n",
      "Iter: 2230 tensor(0.5813, grad_fn=<MeanBackward0>) tensor(0.1646, grad_fn=<MeanBackward0>)\n",
      "Iter: 2240 tensor(0.5812, grad_fn=<MeanBackward0>) tensor(0.0616, grad_fn=<MeanBackward0>)\n",
      "Iter: 2250 tensor(0.5811, grad_fn=<MeanBackward0>) tensor(0.0374, grad_fn=<MeanBackward0>)\n",
      "Iter: 2260 tensor(0.5812, grad_fn=<MeanBackward0>) tensor(0.0605, grad_fn=<MeanBackward0>)\n",
      "Iter: 2270 tensor(0.5817, grad_fn=<MeanBackward0>) tensor(0.0446, grad_fn=<MeanBackward0>)\n",
      "Iter: 2280 tensor(0.5817, grad_fn=<MeanBackward0>) tensor(0.0723, grad_fn=<MeanBackward0>)\n",
      "Iter: 2290 tensor(0.5820, grad_fn=<MeanBackward0>) tensor(0.0381, grad_fn=<MeanBackward0>)\n",
      "Iter: 2300 tensor(0.5819, grad_fn=<MeanBackward0>) tensor(0.0526, grad_fn=<MeanBackward0>)\n",
      "Iter: 2310 tensor(0.5815, grad_fn=<MeanBackward0>) tensor(0.0492, grad_fn=<MeanBackward0>)\n",
      "Iter: 2320 tensor(0.5810, grad_fn=<MeanBackward0>) tensor(0.0502, grad_fn=<MeanBackward0>)\n",
      "Iter: 2330 tensor(0.5805, grad_fn=<MeanBackward0>) tensor(0.0668, grad_fn=<MeanBackward0>)\n",
      "Iter: 2340 tensor(0.5801, grad_fn=<MeanBackward0>) tensor(0.2519, grad_fn=<MeanBackward0>)\n",
      "Iter: 2350 tensor(0.5799, grad_fn=<MeanBackward0>) tensor(0.0646, grad_fn=<MeanBackward0>)\n",
      "Iter: 2360 tensor(0.5804, grad_fn=<MeanBackward0>) tensor(0.0616, grad_fn=<MeanBackward0>)\n",
      "Iter: 2370 tensor(0.5810, grad_fn=<MeanBackward0>) tensor(0.0668, grad_fn=<MeanBackward0>)\n",
      "Iter: 2380 tensor(0.5809, grad_fn=<MeanBackward0>) tensor(0.0971, grad_fn=<MeanBackward0>)\n",
      "Iter: 2390 tensor(0.5809, grad_fn=<MeanBackward0>) tensor(0.0728, grad_fn=<MeanBackward0>)\n",
      "Iter: 2400 tensor(0.5809, grad_fn=<MeanBackward0>) tensor(0.0757, grad_fn=<MeanBackward0>)\n",
      "Iter: 2410 tensor(0.5807, grad_fn=<MeanBackward0>) tensor(0.0635, grad_fn=<MeanBackward0>)\n",
      "Iter: 2420 tensor(0.5812, grad_fn=<MeanBackward0>) tensor(0.0557, grad_fn=<MeanBackward0>)\n",
      "Iter: 2430 tensor(0.5812, grad_fn=<MeanBackward0>) tensor(0.1069, grad_fn=<MeanBackward0>)\n",
      "Iter: 2440 tensor(0.5811, grad_fn=<MeanBackward0>) tensor(0.0374, grad_fn=<MeanBackward0>)\n",
      "Iter: 2450 tensor(0.5809, grad_fn=<MeanBackward0>) tensor(0.0525, grad_fn=<MeanBackward0>)\n",
      "Iter: 2460 tensor(0.5803, grad_fn=<MeanBackward0>) tensor(0.0838, grad_fn=<MeanBackward0>)\n",
      "Iter: 2470 tensor(0.5800, grad_fn=<MeanBackward0>) tensor(0.0622, grad_fn=<MeanBackward0>)\n",
      "Iter: 2480 tensor(0.5796, grad_fn=<MeanBackward0>) tensor(0.0535, grad_fn=<MeanBackward0>)\n",
      "Iter: 2490 tensor(0.5796, grad_fn=<MeanBackward0>) tensor(0.0419, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(2500):\n",
    "    batch_x, batch_dw, batch_y =generate_samples(batch_in=100)\n",
    "    \n",
    "\n",
    "    x_temp=model_PPDE(batch_x,batch_dw)\n",
    "    loss_temp=Loss(x_temp, batch_y)\n",
    "    \n",
    "    if grad_clip: \n",
    "        nn.utils.clip_grad_value_(model_PPDE.parameters(), grad_clip)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss_temp.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    y0_val=model_PPDE.Y0.mean().cpu().detach().numpy()\n",
    "    loss_val=loss_temp.cpu().detach().numpy()\n",
    "    \n",
    "    y0_mean.append(y0_val)\n",
    "    loss_vec.append(loss_val)\n",
    "\n",
    "    if i%10==0:\n",
    "      #  print(\"Iter:\", i,  loss_temp) \n",
    "        print(\"Iter:\", i,  model_PPDE.Y0.mean(), loss_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "07a1a734",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=np.array(y0_mean)\n",
    "loss_var=np.array(loss_vec)\n",
    "iters=np.arange(0,len(y_pred),1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "879d56aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "87d77b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame()\n",
    "df['iter']=iters\n",
    "df['y_pred']=y_pred\n",
    "df['loss_var']=loss_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "55f1f2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('trained_data/method1_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "60368a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58113813"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['y_pred'][2000:].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3f095885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.581476"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.loss_var<=0.1].y_pred[-500:].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344c25a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076127e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecfdcf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f031d551",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
